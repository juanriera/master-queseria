[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "",
    "text": "1 Introducción general\nEste libro trata sobre la enseñanza de algunos métodos básicos de la estadística y la moderna ciencia de datos y su aplicación al entorno industrial. Está concebido de forma práctica con multitud de ejemplos, no sólo industriales, con el objetivo de mostrar los métodos cuantitativos de análisis, y también el razonamiento necesario para dar sentido a los resultados presentados por las herramientas de análisis de datos.\nEl objetivo del libro es acercar a los estudiantes de la Formación Profesional al uso de las herramientas de análisis de datos industriales. El entorno de la industria actual produce un enorme y constante flujo de datos como resultado tanto de la implantación de sistemas de captura automáticos como del aumento de la tecnificación de los puestos de trabajo; se requiere por parte de los profesionales industriales que sean capaces de analizar esta enorme cantidad de datos para transformarlos en información para la decisión. En la empresa industrial actual, son los ingenieros y técnicos de planta, y no estadísticos o ingenieros informáticos, quienes participan diariamente en la presentacion y discusion de los datos y en la toma de decisiones operativas, tanto en los equipos de trabajo como ante la Dirección. Por esta razón, considero necesario proporcionar a los estudiantes de la Formación Profesional un conocimiento básico de los conceptos, herramientas y métodos del análisis de datos, así como de algunas técnicas de presentación y comunicación de la información.\nLa enseñanza de los conceptos estadísticos ha estado, casi siempre, a cargo de profesores con una gran formación en matemáticas. Estos profesores suelen identificar la comprensión de los conceptos estadísticos con su comprensión matemática. Sin embargo, cuando enseñamos estadística industrial, debemos hacer énfasis tanto en las ideas y la comprensión de los conceptos como en su utilización práctica, y reconocer que el razonamiento matemático no es el único camino para la comprensión conceptual.\nLa práctica de la estadística requiere buen juicio y sentido común. Dado que el buen juicio se desarrolla con la experiencia, un curso de iniciación debe presentar unas guías claras de aplicación de los métodos, y no dar por supuestas unas exigencias excesivamente altas sobre la capacidad de juicio analítico de los estudiantes; no sería un planteamiento razonable. Con el fin de desarrollar esta capacidad de juicio analítico he introducido explicaciones detalladas en la mayor parte de los ejemplos. En todos los casos, los ejercicios requerirán del estudiante no sólo una resolución numérica, sino el uso del juicio analítico y la explicación verbal (o escrita) de las decisiones tomadas y conclusiones realizadas. Creo que este planteamiento será mucho más beneficioso a largo plazo que limitarse a una simple resolución numérica.\nMi experiencia industrial me ha mostrado que en las situaciones reales, sobre el terreno, la comprensión práctica de los conceptos es más importante que su rigurosa formulación matemática. Por esta razón, en el desarrollo del contenido del libro he insistido más en la forma de aplicar las herramientas y entender los análisis que en el conocimiento formal de las fórmulas estadísticas y su deducción matemática. He hecho especial hincapié en la utilización de herramientas sencillas, sobre todo gráficas, que casi siempre son una ayuda para comprender la información contenida en un conjunto de datos. El objetivo es proporcionar al estudiante las bases de la metodología del análisis de datos y del análisis estadístico, y cómo puede aplicarse a la resolución de problemas técnicos concretos, más que el conocimiento de la teoría matemática de la estadística.\nHe evitado las explicaciones formales sobre temas estadísticos cuando no son indispensables para su aplicación práctica. Así, por ejemplo, al explicar la media de un conjunto de datos considero más importante entender el concepto físico de “centro de gravedad” que los conceptos estadísticos de esperanza matemática, que no se tocan en este texto. En este sentido, he intentado que el alumno aprenda a diferenciar “en qué consiste” un estadístico, de “cómo se calcula”. Comprender la diferencia entre el concepto y su fórmula de cálculo es fundamental para entender en qué situación debe usarse uno u otro estadístico.\nUn curso de introducción a la estadística y análisis de datos industriales debe ser, ante todo, práctico y orientado a su aplicación en el entorno industrial real. Los principales temas de trabajo estadístico en la industria tienen que ver con la captura de datos, su almacenamiento y su depuración, su descripción utilizando gráficos, la inferencia (intervalos de confianza y tests), la construcción de modelos explicativos, el diseño de los experimentos industriales, el control estadístico de la calidad y la exposición y presentación de resultados. Dado el alcance limitado de este libro, algunos de estos temas se tratarán de forma muy ligera, y necesitarán de un estudio posterior si el alumno tiene interés en profundizar en ellos. A pesar de que los temas más especializados puedan ser importantes en algunas aplicaciones específicas, no preparan al estudiante para lo que se va a encontrar en el terreno en la mayor parte de las ocasiones. En cambio, la resolución de problemas en equipo en un entorno de aprendizaje dinámico enfrentándose a problemas exigentes, y el desarrollo de las habilidades de análisis, de síntesis y de comunicación, tendrán un impacto mucho más positivo.\nHe intentado mostrar la necesidad de que los estudiantes comprendan y apliquen el método científico en el entorno industrial, y no sólo apliquen un recetario de procedimientos de manera automática. Son mucho mas importantes la comprensión y la utilización adecuada del método científico y de las herramientas y gráficos básicos, antes que la aplicación rutinaria y mecánica de determinadas fórmulas matemáticas o métodos sofisticados y complejos que el alumno puede no comprender en toda su profundidad.\nLas industrias líderes destacan por la aplicación intensiva de métodos tales como Six Sigma, Lean Manufacturing, diseño robusto de productos, y otros que hacen un uso intensivo de los datos, tanto de los obtenidos en producción como de los obtenidos en la realización de experimentos bien diseñados. Pero la mejora de la competitividad en estas empresas no se debe tanto a la aplicación de unos u otros métodos, como al desarrollo del juicio analítico de sus equipos humanos y a la aplicación de lo aprendido a la mejora continua de los procesos industriales. Veremos que la experiencia y el conocimiento tecnológico de estos procesos son fundamentales para el desarrollo del buen juicio analítico, y, en consecuencia, para la buena interpretación de los resultados que se obtienen con las herramientas estadísticas y de análisis.\nTratándose de un libro para el uso en la Formación Profesional, considero prioritario que su estudio se oriente al desarrollo de habilidades que sean de aplicación práctica directa en el puesto de trabajo y además faciliten la empleabilidad del estudiante, y no a la obtención de conocimiento abstracto. En la última edición del Informe sobre el futuro del empleo disponible cuando se edita este libro, publicada por el Foro Económico Mundial (WEF) en junio de 2025 (World Economic Forum 2025), el WEF considera que:\nA estas habilidades se suman las dos que más crecen en estos dos últimos años: la IA y el análisis de datos. La voluntad de este libro es proporcionar conocimientos que ayuden al estudiante a desarrollarse en esta dirección.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#a-quién-va-dirigido-este-libro",
    "href": "index.html#a-quién-va-dirigido-este-libro",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "1.1 A quién va dirigido este libro",
    "text": "1.1 A quién va dirigido este libro\nEl libro está orientado a completar la formación técnica de los estudiantes de Formación Profesional, en las especialidades relacionadas con la actividad productiva industrial. También creo que será de utilidad para los técnicos industriales en activo que no han tenido la oportunidad de recibir una adecuada formación en estas metodologías, y que han encontrado dificultad para lanzarse a su aprendizaje mientras desarrollan so actividad profesional. Espero, también, que los profesores de la Formación Profesional en estos ámbitos de competencia encuentren en este documento los elementos de apoyo que les permitan integrar estas enseñanzas en sus respectivos ciclos formativos.\nEn todos los casos, el aprendizaje requerirá de un esfuerzo que quizás será mayor en los estudiantes que no tengan una base mínima en álgebra y cálculo. En estos casos, el trabajo en equipo y la discusión abierta entre compañeros y con los profesores ayudará a la comprensión de los conceptos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#organización-del-libro",
    "href": "index.html#organización-del-libro",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "1.2 Organización del libro",
    "text": "1.2 Organización del libro\nEl libro se estructura en varias partes:\nUna introducción, con dos capítulos:\n\nEl capítulo 1 hace una introducción general al pensamiento estadístico y su aplicación industrial, explica los tipos de datos que nos podemos encontrar en el entorno industrial y los estudios que dan lugar a estos tipos de datos.\nEl capítulo 2 presenta las dos herramientas básicas que se usarán en el libro, la hoja de cálculo y el programa estadístico de código abierto R. Se describen los aspectos básicos del software estadístico R y sus principales aplicaciones en la manipulación, limpieza y análisis de conjuntos de datos. Se introduce también el concepto actual de reproducibilidad, y se explica su importancia y el impacto de utilizar una hoja de cálculo o un análisis basado en un script programado.\n\nLa primera parte introduce las técnicas básicas:\n\nEn el capítulo 3 se presentan conceptos básicos, tales como población, muestra y variable, y se hace una introducción al concepto de flujo de trabajo y al concepto de datos ordenados o tidy data, que resulta fundamental para las fases posteriores de análisis. Se explica también cómo mover datos desde excel a R y viceversa.\nEl capítulo 4 habla de la exploración de los datos como primer paso en el análisis. Se introducen las distribuciones de frecuencia y los principales gráficos que se utilizarán, y se explica cómo hacerlos con Excel y con R.\nEn el capítulo 5 se presentan los principales estadísticos que describen una población, mediante un valor central y una medida de dispersión, tanto paramétricos (media y varianza) como no paramétricos (mediana y rango intercuartil), de forma sencilla y sin recurrir a explicaciones matemáticas o estadísticas avanzadas.\nEl capítulo 6 explica la importancia de comprender la forma de los datos, es decir, su distribución. Se ponen en práctica las herramientas estudiadas en los dos capítulos anteriores para estudiar algunos casos prácticos.\nEn el capítulo 7 se presentan los métodos para detectar la relación entre dos variables (correlación y regresión lineal), haciendo énfasis en los métodos gráficos, y se discuten las diferencias entre correlación y causalidad.\nEl capítulo 8 se hace una breve introducción a las técnicas de comunicación, tanto a la presentación de datos como a la preparación de informes. Se hace hincapié en las nuevas herramientas como Quarto, que facilitan la elaboración de informes automatizados.\n\nLa segunda parte del libro trata algunas conceptos avanzados, pero desarrollados de forma básica; he intentado que estos conceptos puedan comprenderse sin necesidad de desarrollos teóricos o formulaciones complejas.\n\nEl capítulo 9 introduce el concepto de probabilidad, así como las distribuciones de probabilidad, necesarias para la construcción de los tests de hipótesis y, en general, de la estadística inferencial. Este contenido se presenta de forma breve y, sobre todo, práctica.\nEl capítulo 10 introduce de manera sencilla el análisis de la varianza, necesario para métodos importantes en la industria como el control de la precisión analítica, que se trata en un capítulo posterior.\nEn el capítulo 11 se hace una introducción al diseño de experimentos. La utilidad de esta técnica es primordial para el industrial, sobre todo para el área de I+D y el diseño de productos. Dado que esta técnica puede ser muy compleja en su aplicación real, se facilitan enlaces a otros recursos, como cursos, que serán útiles a los que quieran profundizar más.\n\nLa tercera y última parte del libro desarrolla algunas aplicaciones prácticas al entorno industrial de lo estudiado en los capítulos anteriores.\n\nEl capítulo 12 presenta una de las aplicaciones más importantes de la estadística en el entorno industrial, el control estadístico de procesos. Dada la importancia de este capítulo, se refuerza su contenido con numerosos ejemplos y casos prácticos, y se incluye un caso extenso para su análisis.\nEl capítulo 13 trata del análisis del sistema de medición, la calidad de las medidas y la medida de la precisión analítica. Resulta sorprendente la cantidad de laboratorios que dan soporte analítico a procesos productivos de gran impacto económico en la vida de la empresa, sin realizar nunca un autocontrol sobre el nivel de precisión de sus análisis. En este capítulo se hace una presentación básica del tema con el objetivo de que resulte útil y práctica.\nFinalmente, el capítulo 14 explica la aplicación estructurada de los conceptos y técnicas estudiadas en el libro a la mejora de los procesos y la calidad industrial mediante el método Six Sigma.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#cómo-usar-el-libro",
    "href": "index.html#cómo-usar-el-libro",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "1.3 Cómo usar el libro",
    "text": "1.3 Cómo usar el libro\nHe intentado que cada capítulo sea lo más autocontenido posible de forma que se facilite la organización pedagógica por temas. No obstante, a veces puede ser necesario conocer los contenidos de los capítulos anteriores, por lo que se sugiere estudiarlo en el orden presentado.\nEl libro es eminentemente práctico, con numerosos ejercicios; su resolución puede ser individual o en equipo.\nAlgunos recuadros utilizan códigos de color para indicar el objetivo de la información que contienen. Básicamente, los colores utilizados son:\n\n\n\n\n\n\nProblema o cuestión a resolver\n\n\n\nEl recuadro azul se utilizará para proponer problemas sencillos cuya respuesta se encuentra más adelante en el texto. El objetivo de estos problemas es estimular la reflexión, aunque puede ser necesario recurrir a cálculos sencillos ayudados por las herramientas disponibles.\n\n\n\n\n\n\n\n\nRespuesta al problema o explicación del código R\n\n\n\n\n\nEl recuadro verde se utilizará para dos cosas\n\nproponer una respuesta al problema planteado; respuesta que no tiene por qué ser la única posible, o bien\npara explicar las líneas de código R que se mostrarán a continuación\n\nNormalmente se presentará de forma desplegable para no entorpecer la lectura del texto.\n\n\n\nAdemás se incluyen diferentes tipos de avisos cada vez que se introduce algún concepto que es necesario resaltar.\n\n\n\n\n\n\nImportante\n\n\n\nEn este formato se indican cuestiones importantes\n\n\n\n\n\n\n\n\n¡Atención!\n\n\n\nEn este formato se indican cuestiones a las que hay que prestar especial atención o que pueden inducir a error",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#uso-del-ordenador-y-el-software-estadístico",
    "href": "index.html#uso-del-ordenador-y-el-software-estadístico",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "1.4 Uso del ordenador y el software estadístico",
    "text": "1.4 Uso del ordenador y el software estadístico\nEn la práctica diaria, los técnicos industriales usan los ordenadores para almacenar y visualizar los datos de producción, para solucionar problemas mediante análisis estadísticos, y para presentar sus resultados de forma gráfica. De la misma forma que en el entorno industrial, en este libro se utilizarán también los ordenadores de forma habitual, y por esta razón es imprescindible que los estudiantes tengan acceso individual a un ordenador en el que esté instalado el software recomendado, y que se acostumbren a utilizarlo para resolver los problemas y casos planteados como ejercicios prácticos, individualmente y en grupo.\nEl estudiante que se incorpora a una empresa, sea en un laboratorio o en una planta de producción, se va a encontrar muy pronto delante de una hoja de cálculo, y debe saber cómo utilizarla correctamente. Actualmente, lo más probable es que esa hoja de cálculo sea Microsoft Excel, aunque hay otras alternativas posibles, como Google Sheets, Apple Numbers, OpenOffice Calc y algunas más. La gran dominancia en el mercado de Microsoft Excel ha hecho que todas estas herramientas sean totalmente compatibles o tengan modos de compatibilidad con Excel. Por esta razón, este libro se basa en la utilización de Excel como hoja de cálculo y herramienta principal para el almacenamiento de datos.\nA lo largo del libro se presentarán informes y gráficos obtenidos con Microsoft Excel, y también con el software estadístico R. Prácticamente todos ellos pueden ser exportados a otras herramientas, como Google Sheets, OpenOffice, Minitab o Matlab, o analizarse con otros lenguajes de programación, como Python o Julia. En realidad, el método de análisis y cómo obtener un resultado correcto son aspectos más importantes que la herramienta que se utilice para ello, por lo que queda en manos del instructor la decisión final sobre qué usar y cómo. Para facilitar este trabajo de conversión, en su caso, todo el material del libro y los datos de ejemplo estarán disponibles en un repositorio de GitHub.\nAlgunos ejercicios tienen que ver con la interpretación y presentación de los resultados. Es importante que estos trabajos se realicen en grupo y se haga énfasis en la comprensión del problema y en su correcta exposición; en los equipos industriales de hoy, la discusión de problemas y la exposición de resultados, en reuniones de trabajo o en paneles informativos a pie de planta, forma parte del trabajo diario. Estas habilidades de comunicación deben ser desarrolladas en los estudiantes de forma prioritaria.\nLa ventaja de R sobre Excel es que el código R, si está bien documentado, muestra cada paso realizado, y esto permite que otras personas puedan verificar el resultado y reproducirlo a partir de los datos originales, e incluso reutilizar los procedimientos. Utilizar código en vez de clicks de ratón es esencial para asegurar la reproducibilidad de los análisis de datos1. Por esta razón, recomiendo el uso del lenguaje R como complemento o alternativa a la hoja de cálculo, tanto para analizar como para visualizar datos. Sin embargo, como la realidad del mundo de la empresa es que los lenguajes como R están todavía poco introducidos, es inevitable mantener el uso de la hoja de cálculo; en el libro se explicarán algunas mejores prácticas, que permitirán el uso simultáneo de ambas herramientas de forma óptima.\nRespecto a la programación informática, en el libro no se hace énfasis en la programación R más que como sucesión de órdenes individuales en scripts sencillos. No se busca la eficiencia computacional ni la rapidez en el cálculo, sino la comprensión de la metodología de resolución de problemas y cómo ésta se apoya en las herramientas presentadas. De la misma manera, tampoco se hace ningún uso de la programación en Excel, ya sea con macros o con Visual Basic; estos temas quedan fuera del perímetro de este libro.\nUn paso en la dirección de la implantación de flujos de trabajo reproducibles es la elaboración de informes automatizados. Estos informes incluyen el código R, los comentarios del autor en forma de texto formateado en markdown, y los resultados del código. Herramientas como Quarto, o Google Colaboratory, que usa la interface Jupyter, son nuevas formas de elaborar y presentar los informes y resultados estadísticos. En el entorno docente, estas herramientas abren posibilidades muy interesantes en la presentación de un ejercicio o un exámen escrito, ya que el alumno puede detallar perfectamente todos los pasos hasta llegar al resultado final, y facilita la revisión por sus compañeros o por el profesor a cargo de la asignatura.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#sec-aprendizaje",
    "href": "index.html#sec-aprendizaje",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "1.5 Recursos adicionales y cómo usarlos",
    "text": "1.5 Recursos adicionales y cómo usarlos\nEn este libro se hace una introducción muy general a R y a Excel; se presupone que el alumno tiene un conocimiento básico de ambas herramientas. Si no tiene ninguna formación sobre el lenguaje R y el entorno RStudio, recomiendo hacer alguna formación previa sencilla que introduzca los conceptos básicos. Datacamp tiene cursos gratuitos de introducción a R; también hay cursos de formación tanto de R como de Excel en otras plataformas web como edX, Udemy y Coursera, muchos de ellos gratuitos. El Gobierno de España, dentro de una de sus iniciativas de transformación digital, la iniciativa de datos abiertos, incluye también una amplia referencia a cursos de formación sobre R.\nTodos los datos presentados en los ejemplos se incluyen en hojas de cálculo que están disponibles en GitHub. También se incluyen fuentes de datos adicionales que pueden permitir plantear nuevos ejercicios.\nAl final del libro se incluye una bibliografía completa.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#sobre-el-libro",
    "href": "index.html#sobre-el-libro",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "1.6 Sobre el libro",
    "text": "1.6 Sobre el libro\nEl libro ha sido editado en Quarto. Está disponible en PDF.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "Agradecimientos",
    "text": "Agradecimientos\n\n\n\n\n\nWorld Economic Forum. 2025. «Future of Jobs Report, 2025». 91-93 route de la Capite,CH-1223 Cologny/Geneva, Switzerland: World Economic Forum. https://www.weforum.org/publications/the-future-of-jobs-report-2025/.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Introducción al análisis de datos industriales utilizando Microsoft Excel y Python",
    "section": "",
    "text": "El concepto de reproducibilidad, cada vez más importante, se desarrolla en el capítulo 1↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción general</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html",
    "href": "010-introduccion-a-python.html",
    "title": "2  Introducción a Python (1)",
    "section": "",
    "text": "2.1 Cómo usar este cuaderno\nPython es un lenguaje de programación. Para trabajar con el lenguaje, se han desarrollado diferentes interfaces que mejoran el manejo del programa y facilitan el trabajo.\nNosotros utilizaremos Google Colaborate, conocido como Colaboratory o simplemente, Google Colab, basado en el entorno Jupyter, originalmente desarrollado para Python y que se ha convertido en interfase universal de muchos lenguajes de programación.\nEn este entorno, podemos escribir código y ejecutarlo. También podemos escribir en celdas de texto, lo que nos permite intercalar explicaciones a nuestros cálculos o cualquier otro contenido escrito.\nHaciendo click en la barra de opciones a la izquierda sobre la primera opción de índice podemos tener la visión de conjunto del cuaderno",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#cómo-usar-este-cuaderno",
    "href": "010-introduccion-a-python.html#cómo-usar-este-cuaderno",
    "title": "2  Introducción a Python (1)",
    "section": "",
    "text": "Si has abierto un cuaderno ya creado, del que te han pasado un enlace, y estás abriéndolo por primera vez, sigue estos pasos:\n\nGuarda una copia en tu carpeta de Google Drive. Para ello, vete a Archivo/Guardar una copia en Drive y guárdalo.\nUna vez guardada la copia, puedes cambiar el nombre en ’Archivo/Cambiar nombre`, o bien directamente haciendo click sobre el nombre en la parte superior de la hoja.\n\nSi vas a crear una hoja nueva (en blanco) mediante el enlace a Google Colaborate, sigue estos pasos:\n\nAbre la hoja de Google Colaborate escribiendo en la barra de direcciones del navegador: colab.to\nGuarda una copia en Archivo/Guardar una copia como\nRenombra la hoja en Archivo/Cambiar nombre usando el nombre que quieras",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#primeros-pasos",
    "href": "010-introduccion-a-python.html#primeros-pasos",
    "title": "2  Introducción a Python (1)",
    "section": "2.2 Primeros pasos",
    "text": "2.2 Primeros pasos\nEn estos ejercicios usaremos varios archivos de datos de demostración. En el primer cuaderno de introducción veremos archivos ya existentes en diversas fuentes de Python, que nos servirán para hacer diferentes ejercicios numéricos y gráficos. En el segundo cuaderno, utilizaremos exclusivamente un archivo de datos en formato CSV (camembert.csv), que contiene los datos analíticos diarios, de producto terminado, de una fabricación de un queso camembert durante un año; son datos reales.\nEn el entorno jupyter, el texto se introduce en celdas.\nHay dos tipos de celdas: texto y código. En la parte superior de la ventana, puedes elegir el tipo que quieres insertar haciendo click en + Código o bien en + Texto\nPara editar una celda de texto existente, haz doble click sobre ella. Ahora puedes escribir usando las convenciones de código markdown. Cuando hayas terminado, ejecuta la celda para que Colab formatee y presente el texto.\nPara ejecutar una celda de código, haz click sobre ella.\n\nShift-Enterejecuta el código y pasa a la siguiente celda.\nCtrl-Enterejecuta el código y permanece en la misma celda\n\nRecuerda también que las celdas de código deben ejecutarse en orden secuencial desde el principio\nSi la ejecución de una celda de código produce un error, no te preocupes, no tiene consecuencias graves. Simplemente, edita el código y corrige el error. En muchos casos, Google Gemini te puede ayudar a detectar los errores en el código y reescribirlo correctamente.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#cálculos-simples-con-python",
    "href": "010-introduccion-a-python.html#cálculos-simples-con-python",
    "title": "2  Introducción a Python (1)",
    "section": "2.3 Cálculos simples con python",
    "text": "2.3 Cálculos simples con python\nEn su forma más básica, python se puede utilizar como una simple calculadora, utilizando los siguientes operadores aritméticos:\nAdición: \\(+\\) (Ejemplo: \\(2+2\\))\nResta: \\(-\\) (Ejemplo: \\(2-2\\))\nMultiplicación: \\(*\\) (Ejemplo: \\(2*2\\))\nDivisión: \\(/\\) (Ejemplo: \\(2/2\\))\nExponenciación: ** (Ejemplo: \\(2\\)**\\(2\\))\nPrueba a ejecutar las siguientes celdas:\n\n2+2\n\n4\n\n\n\n2-2\n\n0\n\n\n\n2*2\n\n4\n\n\n\n2/2\n\n1.0\n\n\n\n2**2\n\n4\n\n\n\n(3*4)/2\n\n6.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#creación-y-asignación-de-variables",
    "href": "010-introduccion-a-python.html#creación-y-asignación-de-variables",
    "title": "2  Introducción a Python (1)",
    "section": "2.4 Creación y asignación de variables",
    "text": "2.4 Creación y asignación de variables\nUna variable permite almacenar un valor (por ejemplo, 4) o un objeto (por ejemplo, una descripción de función). Más tarde se puede usar el nombre de esta variable para acceder fácilmente al valor o al objeto que está almacenado dentro de ella.\nPodemos imaginar este concepto como una estantería llena de celdas vacías, en las cuales podemos colocar diferentes objetos: números, letras, frases, etc La variable es el espacio que almacena un valor, y que podemos llamar u obtener simplemente escribiendo su nombre.\nEn python, una variable es un objeto. Podemos asignar valores a ese objeto, como si colocásemos libros en nuestra estantería. Esta asignación se hace siempre con el operador de asignación =, en la forma\n\\(nombre\\_de\\_objeto = valor\\)\nPor ejemplo, asignaremos un valor 4 a una variable que se llame mi_var con el operador de asignación de la siguiente forma:\n\\(mi\\_var = 4\\)\nRecuerda que ahora estamos en una celda de texto; prueba a hacer la asignación en la celda de código a continuación, añadiendo el operador de asignación y ejecutando la celda con Mayus-Intro:\n\nmi_var 4\n\nUna vez que asignamos un valor a una variable, python recuerda su valor hasta que lo cambiemos mediante una nueva asignación, borremos la variable, o finalicemos nuestra sesión.\nPara ver el contenido del objeto(lo que hemos almacenado en mi_var), escribimos el nombre y ejecutamos la celda (sólo si hemos editado y ejecutado correctamente la celda anterior, en caso contrario obtendremos un error porque mi_var no está definida):\n\nmi_var",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#cómo-establecer-los-nombres-de-variables",
    "href": "010-introduccion-a-python.html#cómo-establecer-los-nombres-de-variables",
    "title": "2  Introducción a Python (1)",
    "section": "2.5 Cómo establecer los nombres de variables",
    "text": "2.5 Cómo establecer los nombres de variables\nPara facilitar la legibilidad del código, los nombres de variables en python deben cumplir algunas normas generales. Buscaremos siempre que los nombres de los objetos sean descriptivos, por lo que necesitamos una forma de unir varias palabras.\nLas convenciones más aceptadas para la designación de nombres de variables en Python se basan principalmente en la PEP 8, la guía de estilo oficial para el código Python. Aquí te resumo los puntos clave:\n\nSnake Case (Recomendado para variables y funciones):\n\nPara nombres de variables y funciones que constan de varias palabras, se utiliza snake_case, donde las palabras se escriben en minúscula y se separan por guiones bajos.\nEjemplos: mi_variable, nombre_completo, calcular_total.\n\nCamel Case (Para clases):\n\nPara nombres de clases, se utiliza CamelCase (también conocido como PascalCase), donde cada palabra comienza con mayúscula y no hay separadores.\nEjemplos: MiClase, GestionDeUsuarios, HttpRequest.\n\nConstantes (Mayúsculas con guiones bajos):\n\nPara constantes (variables cuyo valor no debería cambiar durante la ejecución del programa), se utiliza ALL_CAPS con guiones bajos para separar las palabras.\nEjemplos: MAX_VALOR, PI, TASA_INTERES.\n\nReglas generales (obligatorias por el lenguaje):\n\nLongitud: Las variables pueden tener cualquier longitud.\nCaracteres permitidos: Pueden contener letras (mayúsculas y minúsculas), números y guiones bajos (_).\nNo pueden empezar con un número: Un nombre de variable no puede comenzar con un dígito.\nSensibilidad a mayúsculas y minúsculas: Python distingue entre mayúsculas y minúsculas. mi_variable y Mi_Variable son nombres de variables diferentes.\nEvitar palabras reservadas: No se pueden usar palabras reservadas de Python (como if, else, for, while, etc.) como nombres de variables.\nNo usar caracteres especiales: No se permiten espacios, signos de puntuación u otros símbolos especiales.\n\nRecomendaciones de estilo:\n\nNombres descriptivos: Elige nombres de variables que sean claros y descriptivos, que reflejen su propósito en el programa. Esto mejora la legibilidad del código.\nEvitar nombres de una sola letra: A menos que sean contadores simples (i, j, k en bucles) o iteradores, es mejor evitar nombres de variables de una sola letra.\nEvitar nombres que se confundan: Ten cuidado con letras que pueden confundirse fácilmente, como la l minúscula y el número 1, o la O mayúscula y el número 0.\nGuiones bajos al principio (_nombre): Un solo guion bajo al principio (_) suele indicar que una variable o función es “interna” o “no pública” dentro de un módulo o clase. Es una convención, no una restricción estricta.\nDobles guiones bajos al principio (__nombre): Los dobles guiones bajos al principio de un nombre de atributo de clase (__nombre) activan el “name mangling” (mutilación de nombre) de Python, que hace que el atributo sea más difícil de acceder directamente desde fuera de la clase, actuando como una forma de “privacidad”.\n\n\nSeguir estas convenciones, especialmente las de la PEP 8, ayuda a que tu código sea más consistente, legible y fácil de entender por otros desarrolladores (y por ti mismo en el futuro).\nUsemos un nombre realmente largo para designar a una variable:\n\neste_es_un_nombre_realmente_largo = 5.3\n\nAhora recuperemos el valor que hemos almacenado\n\neste_es_un_nombre_realmente_largo\n\n5.3\n\n\nRecuerda que python utiliza la escritura anglosajona para la separación de decimales, usando un punto, y no una coma como en España. ¿Qué pasaría si utilizamos una coma para separar los decimales?\n\nmi_var = 2,5\n\nPython acepta la asignación, pero cuando investigamos la variable, el resultado es diferente de lo que esperábamos, no obtenemos un valor numérico:\n\nmi_var\n\n(2, 5)\n\n\nPython ha entendido que estábamos creando una tupla de dos valores (2 y 5) (en python, una tupla es una colección ordenada e inmutable de elementos)\nPara python las mayúsculas y minúsculas son diferentes: mi_var y mi_Var son variables diferentes.\nEn una variable python podemos almacenar también texto:\n\nmi_var = \"Esto es una frase 12345\"\n\nPython almacena esta cadena alfanumérica exactamente igual que antes hizo con los valores numéricos:\n\nmi_var\n\n'Esto es una frase 12345'\n\n\n\nmi_var = 123.45\n\n\nmi_var\n\n123.45\n\n\n\nmi_var*5\n\n617.25\n\n\nPara almacenar una cadena alfanumérica necesitamos encerrarla entre comillas, ya sean sencillas o dobles. De hecho, si almacenamos un número entre comillas, python no va aidentificarlo como un número, sino como un texto:\n\nmi_var = \"123.45\"\n\n\nmi_var\n\n'123.45'\n\n\n\nmi_var*5\n\n'123.45123.45123.45123.45123.45'\n\n\nComo ahora mi_var es una cadena de letras, python interpreta mi_var*5no como una multiplicación, sino como una instrucción para repetir esa cadena de caracteres cinco veces.\nEn el ejemplo que acabamos de hacer, seguro que te has dado cuenta de que python permite reutilizar los objetos simplemente reasignándoles el valor correspondiente. Al hacerlo, perdemos el valor original y lo sustituimos por el nuevo valor.\nHay que tener atención con las reglas de escritura: para asignar un texto a un objeto debemos tener cuidado de cerrar las comillas, si no lo hacemos, python nos advertirá del error:\n\nmi_var = \"Esto es una cadena alfanumerica que no hemos cerrado\n\n\nAlgunos ejercicios\nIntenta detectar los errores en las siguientes celdas de código:\n\nmi_variable = 10\nmi_varıable\n\n\nmi_var = 5\nMi_Var\n\nPodemos asignar un objeto a otro objeto con el operador de asignación:\n\nx = 5\ny = 3\n\n\nx + y\n\n8\n\n\n\ny = x\n\n\nx + y\n\n10\n\n\nSupongamos que tenemos 5 peras y 4 manzanas. Crea una variable que se llame fruta que sume el total de unidades de fruta que tenemos, insertando debajo de esta celda todas las celdas de código que necesites (Pista: ¡En python sí podemos sumar peras con manzanas!)\n\n# Celda para el ejercicio de las frutas\nperas = 5\nmanzanas = 4\nfruta = peras + manzanas\nprint(fruta)\n\n9",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#los-tipos-de-datos",
    "href": "010-introduccion-a-python.html#los-tipos-de-datos",
    "title": "2  Introducción a Python (1)",
    "section": "2.6 Los tipos de datos",
    "text": "2.6 Los tipos de datos\nHemos visto que python puede trabajar con diferentes tipos de datos, tales como números y textos.\nLos valores decimales como 4.5 se llaman flotantes(float). Los números enteros como 4 se llaman enteros(ìnt). Los valores booleanos (VERDADERO o FALSO) se denominan booleanos(bool o logical). Los valores de texto (o cadena alfanumérica) se denominan cadenas de caracteres. También se les llama simplemente cadenas. Las comillas en el editor indican que “un texto entre comillas” es una cadena de caracteres. En python, una cadena de caracteres puede escribirse entre comillas dobles, como \"pera\" o simples, como 'pera'\nAlgunos ejemplos:\n\nmi_var_numero = 4.5\nmi_var_texto = \"esto es un texto\"\nmi_var_texto_2 = 'esto también es un texto'\nmi_var_logica = False\n\nLas variables lógicas pueden tomar los valores True o False (recuerda que las mayúsculas son significativas en python: False no es lo mismo que false o FALSE). Python responde también con un valor lógico cuando hacemos una evaluación lógica. Por ejemplo,\n\nmi_var_numero == 4.5\n\nTrue\n\n\n\nmi_var_texto == 4.5\n\nFalse\n\n\nComo en python se usa = como operador de asignación, el operador lógico que prueba una igualdad es ==, un doble igual, y no un =, un igual sencillo.\nVeamos otros dos ejemplos que proporcionan una respuesta de valor lógico:\n\nmi_var_numero == 10\n\nFalse\n\n\n\nmi_var_numero &gt; 5\n\nFalse\n\n\n\nmi_var_numero != 5 # el operador != significa \"no es igual a\"\n\nTrue",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#las-funciones-en-python-qué-son-y-por-qué-las-usamos",
    "href": "010-introduccion-a-python.html#las-funciones-en-python-qué-son-y-por-qué-las-usamos",
    "title": "2  Introducción a Python (1)",
    "section": "2.7 Las Funciones en Python: ¿Qué son y por qué las usamos?",
    "text": "2.7 Las Funciones en Python: ¿Qué son y por qué las usamos?\nHasta ahora hemos usado operadores aritméticos para realizar cálculos básicos y hemos asignado valores a variables. Pero, ¿qué pasa si queremos realizar tareas más complejas o repetir una misma operación muchas veces? Aquí es donde entran las funciones.\nUna función es un bloque de código organizado y reutilizable que se utiliza para realizar una única acción relacionada. Piensa en una función como una “receta” o un “mini-programa” que encapsula una serie de pasos. En lugar de escribir esos pasos una y otra vez, simplemente “llamamos” a la función por su nombre.\n¿Por qué son útiles las funciones?\n\nReutilización de Código: Evitan tener que escribir el mismo código varias veces.\nModularidad: Dividen el programa en partes más pequeñas y manejables.\nClaridad: Hacen el código más fácil de leer y entender.\n\nPython ya trae consigo muchas funciones integradas (built-in functions) que podemos usar directamente. Veamos algunos ejemplos muy comunes:\n\nprint(): Mostrar información\nEsta función ya la hemos usado. Nos permite mostrar valores, texto o el contenido de variables en la consola\n\nprint(\"¡Hola, esto es una función!\")\nmi_nombre = \"Juan\"\nprint(\"Mi nombre es:\", mi_nombre)\n\n¡Hola, esto es una función!\nMi nombre es: Juan\n\n\n\n\nlen(): Obtener la longitud\nEsta función nos devuelve el número de elementos de un objeto, como el número de caracteres en una cadena de texto o el número de elementos en una lista.\n\nfrase = \"Programar en Python es divertido\"\nlongitud_frase = len(frase)\nprint(\"La frase tiene\", longitud_frase, \"caracteres.\")\n\nmi_lista_numeros = [10, 20, 30, 40]\nprint(\"Mi lista tiene\", len(mi_lista_numeros), \"elementos.\")\n\nLa frase tiene 32 caracteres.\nMi lista tiene 4 elementos.\n\n\n\n\ntype(): Conocer el tipo de dato\nÚtil para verificar qué tipo de dato tiene una variable.\n\nmi_numero = 100\nmi_texto = \"Cien\"\nmi_booleano = True\n\nprint(type(mi_numero))\nprint(type(mi_texto))\nprint(type(mi_booleano))\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n&lt;class 'bool'&gt;\n\n\n\n\n¿Cómo funcionan las funciones? Argumentos y Retorno\n\nArgumentos: Muchas funciones necesitan información para poder trabajar. Esta información se les pasa entre paréntesis, y se llaman argumentos. Por ejemplo, a print() le pasamos lo que queremos mostrar.\nRetorno de Valores: Algunas funciones realizan un cálculo o una operación y nos devuelven un resultado. Por ejemplo, len() nos devuelve un número.\n\nEntender las funciones es clave, porque las librerías que usaremos a continuación son, en esencia, grandes colecciones de funciones especializadas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#importando-herramientas-bibliotecas-y-módulos",
    "href": "010-introduccion-a-python.html#importando-herramientas-bibliotecas-y-módulos",
    "title": "2  Introducción a Python (1)",
    "section": "2.8 Importando Herramientas: Bibliotecas y Módulos",
    "text": "2.8 Importando Herramientas: Bibliotecas y Módulos\nPython es un lenguaje muy potente, pero su verdadera fuerza reside en su vasto ecosistema de bibliotecas (también llamadas módulos o paquetes).\nUna biblioteca es una colección de código (funciones, clases, etc.) escrito por otros programadores y disponible para que tú lo uses en tus propios proyectos. Imagina que son “cajas de herramientas” especializadas:\n\n¿Necesitas hacer cálculos matemáticos complejos? Hay una librería para eso.\n¿Necesitas manipular datos en tablas? Hay una librería para eso.\n¿Necesitas crear gráficos? ¡También hay librerías para eso!\n\nUsar librerías nos permite evitar “reinventar la rueda”, ahorrando mucho tiempo y esfuerzo, y aprovechando código que ya ha sido probado y optimizado.\nPara poder usar las funciones y herramientas que están dentro de una librería, primero debemos importarla a nuestro entorno de trabajo. La forma más común de hacerlo es con la instrucción import.\n\nSintaxis de import\nLa sintaxis básica es:\nimport nombre_de_la_libreria\nSin embargo, para las librerías de análisis de datos, es muy común y recomendado usar un alias (un nombre corto) para hacer el código más conciso y fácil de leer. Esto se hace con la palabra clave as:\nimport nombre_de_la_libreria as alias\nAhora vamos a importar las librerías que serán esenciales para trabajar con datos, realizar cálculos estadísticos y crear gráficos en Python.\n\n# Importando las librerías fundamentales para el análisis de datos\n\n# Pandas: Es la librería principal para trabajar con estructuras de datos tabulares\n#         como Series (vectores) y DataFrames (tablas).\nimport pandas as pd\n\n# NumPy: Proporciona soporte para arreglos (arrays) y matrices multidimensionales,\n#        además de funciones matemáticas de alto nivel. Pandas se construye sobre NumPy.\nimport numpy as np\n\n# Matplotlib.pyplot: Es la librería base para crear gráficos en Python.\n#                    Seaborn la usa \"por debajo\" para dibujar.\nimport matplotlib.pyplot as plt\n\n# Seaborn: Es una librería de visualización de datos de alto nivel\n#          basada en Matplotlib. Facilita la creación de gráficos estadísticos atractivos.\nimport seaborn as sns\n\nprint(\"¡Librerías principales para el análisis de datos importadas correctamente!\")\nprint(\"Ahora podemos acceder a sus funciones usando sus alias (pd, np, plt, sns).\")\n\n¡Librerías principales para el análisis de datos importadas correctamente!\nAhora podemos acceder a sus funciones usando sus alias (pd, np, plt, sns).\n\n\nUna vez que hemos importado una librería con un alias (por ejemplo, pandas as pd), para usar una función de esa librería, escribimos el alias seguido de un punto y el nombre de la función: pd.nombre_de_la_funcion().",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#las-principales-estructuras-de-datos-en-python-para-el-análisis",
    "href": "010-introduccion-a-python.html#las-principales-estructuras-de-datos-en-python-para-el-análisis",
    "title": "2  Introducción a Python (1)",
    "section": "2.9 Las principales estructuras de datos en Python para el análisis",
    "text": "2.9 Las principales estructuras de datos en Python para el análisis\nAhora que entendemos las funciones y cómo importar librerías, podemos introducir las estructuras de datos que nos permitirán organizar y manipular nuestros datos de manera eficiente. Las dos más importantes en el contexto del análisis de datos con Python (y con la librería Pandas) son las Series y los DataFrames.\n\nSeries de Pandas (El “Vector” en Python para datos)\nSi en otros lenguajes de programación o herramientas estadísticas has trabajado con el concepto de “vector” (una secuencia de valores de un mismo tipo), el equivalente más directo en Python, usando Pandas, es una Serie.\n\nConcepto: Una Serie de Pandas es un arreglo unidimensional (como una columna de una hoja de cálculo o un vector). Puede contener cualquier tipo de dato (números enteros, flotantes, texto, booleanos, etc.) y tiene un índice asociado para acceder a sus elementos.\n\nCreación de una Serie: Podemos crear una Serie a partir de una lista de Python.\n\n# Crear una lista de edades\nlista_edades = [25, 30, 22, 35, 28, 40, 33, 29]\n\n# Convertir la lista a una Serie de Pandas\n# Usamos 'pd.' porque la función Series() viene de la librería Pandas\nedades_serie = pd.Series(lista_edades)\n\nprint(\"Mi Serie de Edades:\")\nprint(edades_serie)\n\nMi Serie de Edades:\n0    25\n1    30\n2    22\n3    35\n4    28\n5    40\n6    33\n7    29\ndtype: int64\n\n\nOperaciones Básicas con Series: Las Series tienen muchas funciones y métodos útiles. Por ejemplo, podemos calcular la media:\n\nprint(\"\\nEdad promedio:\", edades_serie.mean()) # Usando el método .mean() de la Serie\nprint(\"Edad máxima:\", edades_serie.max())\nprint(\"Edad mínima:\", edades_serie.min())\n\n\nEdad promedio: 30.25\nEdad máxima: 40\nEdad mínima: 22\n\n\n\n\nDataFrames de Pandas (La “Tabla” o “Hoja de Cálculo”)\nEl DataFrame es la estructura de datos más importante y utilizada en Pandas para el análisis de datos. Es el equivalente a una tabla en una base de datos, una hoja de cálculo de Excel, o un “data frame” en R.\n\nConcepto: Un DataFrame es una estructura bidimensional (filas y columnas). Piensa en ella como una colección de Series (columnas) que comparten el mismo índice (las filas). Cada columna en un DataFrame es una Serie de Pandas.\n\nCreación de un DataFrame (a partir de un diccionario): Una forma sencilla de crear un DataFrame pequeño es a partir de un diccionario de Python, donde las claves del diccionario se convierten en los nombres de las columnas y los valores son listas que se convierten en las columnas.\n\n# Crear un diccionario con datos\ndatos_alumnos = {\n    'Nombre': ['Ana', 'Luis', 'Marta', 'Pedro', 'Sofía'],\n    'Edad': [24, 30, 28, 35, 26],\n    'Ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Málaga'],\n    'Calificación': [8.5, 7.2, 9.1, 6.8, 8.9]\n}\n\n# Crear un DataFrame a partir del diccionario\ndf_alumnos = pd.DataFrame(datos_alumnos)\n\nprint(\"\\nDataFrame de Alumnos:\")\nprint(df_alumnos)\n\n\nDataFrame de Alumnos:\n  Nombre  Edad     Ciudad  Calificación\n0    Ana    24     Madrid           8.5\n1   Luis    30  Barcelona           7.2\n2  Marta    28   Valencia           9.1\n3  Pedro    35    Sevilla           6.8\n4  Sofía    26     Málaga           8.9\n\n\nVisualización y exploración básica de DataFrames:\nEs fundamental poder echar un vistazo rápido a los datos una vez que están cargados en un DataFrame.\n\ndf.head(): Muestra las primeras 5 filas (útil para ver la estructura).\ndf.tail(): Muestra las últimas 5 filas.\ndf.info(): Proporciona un resumen conciso del DataFrame, incluyendo el número de entradas, columnas, tipos de datos no nulos y uso de memoria.\ndf.describe(): Genera estadísticas descriptivas (conteo, media, desviación estándar, etc.) de las columnas numéricas.\n\n\nprint(\"\\nPrimeras 3 filas del DataFrame de alumnos:\")\nprint(df_alumnos.head(3)) # Podemos especificar el número de filas\n\nprint(\"\\nInformación del DataFrame de alumnos:\")\ndf_alumnos.info()\n\nprint(\"\\nEstadísticas descriptivas del DataFrame de alumnos:\")\nprint(df_alumnos.describe())\n\n\nPrimeras 3 filas del DataFrame de alumnos:\n  Nombre  Edad     Ciudad  Calificación\n0    Ana    24     Madrid           8.5\n1   Luis    30  Barcelona           7.2\n2  Marta    28   Valencia           9.1\n\nInformación del DataFrame de alumnos:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 5 entries, 0 to 4\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Nombre        5 non-null      object \n 1   Edad          5 non-null      int64  \n 2   Ciudad        5 non-null      object \n 3   Calificación  5 non-null      float64\ndtypes: float64(1), int64(1), object(2)\nmemory usage: 292.0+ bytes\n\nEstadísticas descriptivas del DataFrame de alumnos:\n            Edad  Calificación\ncount   5.000000      5.000000\nmean   28.600000      8.100000\nstd     4.219005      1.036822\nmin    24.000000      6.800000\n25%    26.000000      7.200000\n50%    28.000000      8.500000\n75%    30.000000      8.900000\nmax    35.000000      9.100000\n\n\nSelección de Columnas en un DataFrame:\nPara trabajar con una columna específica de un DataFrame, la seleccionamos usando corchetes [] y el nombre de la columna entre comillas. El resultado será una Serie de Pandas.\n\n# Seleccionar la columna 'Edad'\nedades_alumnos = df_alumnos['Edad']\nprint(\"\\nColumna 'Edad' (como Serie):\")\nprint(edades_alumnos)\n\n# Calcular la media de la columna 'Calificación'\nmedia_calificacion = df_alumnos['Calificación'].mean()\nprint(f\"\\nLa calificación promedio de los alumnos es: {media_calificacion:.2f}\")\n\n\nColumna 'Edad' (como Serie):\n0    24\n1    30\n2    28\n3    35\n4    26\nName: Edad, dtype: int64\n\nLa calificación promedio de los alumnos es: 8.10",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#el-data-frame-continuación-con-ejemplo-real",
    "href": "010-introduccion-a-python.html#el-data-frame-continuación-con-ejemplo-real",
    "title": "2  Introducción a Python (1)",
    "section": "2.10 El data frame (continuación con ejemplo real)",
    "text": "2.10 El data frame (continuación con ejemplo real)\nAhora que conocemos los DataFrames, podemos entender mejor cómo leer datos reales. El marco de datos o data frame es el objeto más útil y más usado en el análisis de datos. Consiste en una estructura de dos dimensiones, formada por una serie de vectores de igual longitud, igual que una tabla de una hoja de cálculo, en la que cada columna es una variable y cada fila, un caso, observación o individuo. Algunas bibliotecas Python incluyen data frames de muestra, que son útiles para entender cómo están formados.\nVeamos uno de ellos, el famoso conjunto de datos iris, creada por el investigador y estadístico Ronald Fisher, que contiene un conjunto de medidas realizadas sobre flores del género Iris realizadas por este investigador en los años 30 del siglo XX.\nPara cargar este conjunto de datos de ejemplo, vamos a utilizar una función de la librería seaborn que ya importamos:\n\n# Cargamos el dataset 'iris' usando una función de Seaborn\ndf_iris_sns = sns.load_dataset('iris')\n\nprint(\"Primeras 5 filas del dataset Iris:\")\nprint(df_iris_sns.head())\n\nPrimeras 5 filas del dataset Iris:\n   sepal_length  sepal_width  petal_length  petal_width species\n0           5.1          3.5           1.4          0.2  setosa\n1           4.9          3.0           1.4          0.2  setosa\n2           4.7          3.2           1.3          0.2  setosa\n3           4.6          3.1           1.5          0.2  setosa\n4           5.0          3.6           1.4          0.2  setosa\n\n\nLa función head() es útil para presentarnos sólo el encabezado del data frame. Veamos la estructura de este data frame más a fondo:\n\nprint(\"\\nInformación general del DataFrame Iris:\")\ndf_iris_sns.info()\n\n\nInformación general del DataFrame Iris:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n\n\n\nprint(\"\\nEstadísticas descriptivas de las columnas numéricas del DataFrame Iris:\")\nprint(df_iris_sns.describe())\n\n\nEstadísticas descriptivas de las columnas numéricas del DataFrame Iris:\n       sepal_length  sepal_width  petal_length  petal_width\ncount    150.000000   150.000000    150.000000   150.000000\nmean       5.843333     3.057333      3.758000     1.199333\nstd        0.828066     0.435866      1.765298     0.762238\nmin        4.300000     2.000000      1.000000     0.100000\n25%        5.100000     2.800000      1.600000     0.300000\n50%        5.800000     3.000000      4.350000     1.300000\n75%        6.400000     3.300000      5.100000     1.800000\nmax        7.900000     4.400000      6.900000     2.500000\n\n\nPara utilizar una columna de un dataframe, la seleccionamos por su nombre:\n\nprint(\"\\nContenido de la columna 'sepal_length':\")\nprint(df_iris_sns[\"sepal_length\"])\n\n\nContenido de la columna 'sepal_length':\n0      5.1\n1      4.9\n2      4.7\n3      4.6\n4      5.0\n      ... \n145    6.7\n146    6.3\n147    6.5\n148    6.2\n149    5.9\nName: sepal_length, Length: 150, dtype: float64\n\n\nAhora que tenemos una columna seleccionada (que es una Serie de Pandas), podemos aplicar directamente funciones estadísticas sobre ella:\n\n# Calculamos la media de la columna 'sepal_length'\nmedia_sepal_length = df_iris_sns[\"sepal_length\"].mean()\nprint(f\"\\nLa longitud media del sépalo es: {media_sepal_length:.2f}\")\n\n\nLa longitud media del sépalo es: 5.84\n\n\n\n# También podemos calcular la desviación estándar\ndesviacion_sepal_length = df_iris_sns[\"sepal_length\"].std()\nprint(f\"La desviación estándar de la longitud del sépalo es: {desviacion_sepal_length:.2f}\")\n\nLa desviación estándar de la longitud del sépalo es: 0.83\n\n\nCon nuestros DataFrames cargados y la comprensión de las Series, podemos realizar rápidamente cálculos estadísticos básicos sobre nuestras columnas numéricas. Pandas hace que esto sea muy sencillo.\n\nEstadísticas Descriptivas Comunes:\n\n.mean(): Media\n.median(): Mediana\n.std(): Desviación estándar\n.min(): Valor mínimo\n.max(): Valor máximo\n.sum(): Suma de todos los valores\n.count(): Número de valores no nulos\n\n\nVamos a aplicar algunas de estas operaciones al DataFrame df_iris_sns:\n\nprint(\"Estadísticas de 'petal_width' en el DataFrame Iris:\")\nprint(f\"Media de petal_width: {df_iris_sns['petal_width'].mean():.2f}\")\nprint(f\"Mediana de petal_width: {df_iris_sns['petal_width'].median():.2f}\")\nprint(f\"Desviación estándar de petal_width: {df_iris_sns['petal_width'].std():.2f}\")\nprint(f\"Valor mínimo de petal_width: {df_iris_sns['petal_width'].min():.2f}\")\nprint(f\"Valor máximo de petal_width: {df_iris_sns['petal_width'].max():.2f}\")\nprint(f\"Número de observaciones de petal_width: {df_iris_sns['petal_width'].count()}\")\n\nEstadísticas de 'petal_width' en el DataFrame Iris:\nMedia de petal_width: 1.20\nMediana de petal_width: 1.30\nDesviación estándar de petal_width: 0.76\nValor mínimo de petal_width: 0.10\nValor máximo de petal_width: 2.50\nNúmero de observaciones de petal_width: 150",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#visualización-de-datos-con-seaborn-y-matplotlib",
    "href": "010-introduccion-a-python.html#visualización-de-datos-con-seaborn-y-matplotlib",
    "title": "2  Introducción a Python (1)",
    "section": "2.11 Visualización de Datos con Seaborn y Matplotlib",
    "text": "2.11 Visualización de Datos con Seaborn y Matplotlib\nUna imagen vale más que mil palabras, y en el análisis de datos, la visualización es fundamental para entender patrones, distribuciones y relaciones en nuestros datos. En Python, las librerías Matplotlib y Seaborn son las herramientas estándar para crear gráficos.\n\nMatplotlib.pyplot (alias plt): Es la base, una librería de bajo nivel que da un control muy granular sobre cada aspecto del gráfico.\nSeaborn (alias sns): Construye sobre Matplotlib, ofreciendo una interfaz de alto nivel para crear gráficos estadísticos complejos y estéticamente agradables con menos código. Es ideal para explorar distribuciones, relaciones entre variables y comparaciones entre grupos.\n\nSiempre importamos ambas, ya que Seaborn a menudo usa funciones de Matplotlib para mostrar y personalizar los gráficos (como plt.title() para el título o plt.show() para mostrar el gráfico).\n\nEjemplo 1: Histograma de la longitud del sépalo (Distribución de una variable numérica)\nUn histograma nos permite ver cómo se distribuyen los valores de una variable numérica.\n\n# Crear un histograma de la columna 'sepal_length'\nplt.figure(figsize=(8, 5)) # Define el tamaño de la figura (ancho, alto)\nsns.histplot(data=df_iris_sns, x='sepal_length', kde=True) # kde=True añade una estimación de densidad\nplt.title('Distribución de la Longitud del Sépalo') # Título del gráfico\nplt.xlabel('Longitud del Sépalo (cm)') # Etiqueta del eje X\nplt.ylabel('Frecuencia') # Etiqueta del eje Y\nplt.grid(True, linestyle='--', alpha=0.7) # Añadir una cuadrícula opcional\nplt.show() # Muestra el gráfico\n\n\n\n\n\n\n\n\n\n\nEjemplo 2: Diagrama de dispersión de la longitud vs. ancho del sépalo (Relación entre dos variables numéricas)\nUn diagrama de dispersión es excelente para visualizar la relación entre dos variables numéricas. Podemos añadir un color (hue) para diferenciar por una tercera variable categórica (como la especie de la flor).\n\n# Crear un diagrama de dispersión de sepal_length vs. sepal_width\nplt.figure(figsize=(9, 6))\nsns.scatterplot(data=df_iris_sns, x='sepal_length', y='sepal_width', hue='species', s=80, alpha=0.7)\nplt.title('Longitud vs. Ancho del Sépalo por Especie de Iris')\nplt.xlabel('Longitud del Sépalo (cm)')\nplt.ylabel('Ancho del Sépalo (cm)')\nplt.legend(title='Especie') # Mostrar leyenda para la especie\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEjemplo 3: Gráfico de cajas (Box Plot) de la longitud del pétalo por especie (Comparación de una numérica por una categórica)\nLos box plots son útiles para visualizar la distribución de una variable numérica para diferentes categorías.\n\n# Crear un box plot de petal_length agrupado por 'species'\nplt.figure(figsize=(9, 6))\nsns.boxplot(data=df_iris_sns, x='species', y='petal_length')\nplt.title('Distribución de la Longitud del Pétalo por Especie')\nplt.xlabel('Especie de Iris')\nplt.ylabel('Longitud del Pétalo (cm)')\nplt.grid(axis='y', linestyle='--', alpha=0.7) # Cuadrícula solo en el eje Y\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEjemplo 4: Gráfico de series utilizando pandas.\nUsa la biblioteca pandas y el dataset air_quality que tenemos que bajar del sitio oficial de pandas\n\n# Cargar el dataset desde URL oficial de pandas\nurl = \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2.csv\"\ndf = pd.read_csv(url, parse_dates=[\"datetime\"])\n\n# Establecer fecha como índice\ndf.set_index(\"datetime\", inplace=True)\nprint(df.head())\n\n                     station_antwerp  station_paris  station_london\ndatetime                                                           \n2019-05-07 02:00:00              NaN            NaN            23.0\n2019-05-07 03:00:00             50.5           25.0            19.0\n2019-05-07 04:00:00             45.0           27.7            19.0\n2019-05-07 05:00:00              NaN           50.4            16.0\n2019-05-07 06:00:00              NaN           61.9             NaN\n\n\n\nprint(df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 1035 entries, 2019-05-07 02:00:00 to 2019-06-21 02:00:00\nData columns (total 3 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   station_antwerp  95 non-null     float64\n 1   station_paris    1004 non-null   float64\n 2   station_london   969 non-null    float64\ndtypes: float64(3)\nmemory usage: 32.3 KB\nNone\n\n\n\ndf.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\ndf.station_paris.plot()\nplt.show()\n\n\n\n\n\n\n\n\nVamos a probar con un dataset diferente, el set flights incluido en seaborn, que proporciona los pasajeros por mes en un aeropuerto, durante varios años.\n\n# Cargar dataset\ndf = sns.load_dataset('flights') # load_dataset() es una función de seaborn\ndf.head()\n\n\n\n\n\n\n\n\nyear\nmonth\npassengers\n\n\n\n\n0\n1949\nJan\n112\n\n\n1\n1949\nFeb\n118\n\n\n2\n1949\nMar\n132\n\n\n3\n1949\nApr\n129\n\n\n4\n1949\nMay\n121\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 144 entries, 0 to 143\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   year        144 non-null    int64   \n 1   month       144 non-null    category\n 2   passengers  144 non-null    int64   \ndtypes: category(1), int64(2)\nmemory usage: 2.9 KB\n\n\nComo la columna month está en inglés y tiene formato category, vamos a crear una nueva columna fecha con formato DateTime, que además convertiremos en index, de manera que pandas pueda representar las series temporales correctamente:\n\nAñadir blockquote\n\n\ndf['fecha'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str), format='%Y-%b')\n\n¿Qué hace esta línea?\nCrea una nueva columna llamada fecha en el DataFrame df, combinando las columnas year y month para formar una fecha completa, y luego la convierte al tipo datetime64[ns], que es el formato estándar de fechas en pandas.\n🔍 Paso a paso\n\ndf['year'].astype(str) Convierte la columna year (numérica) a texto. Ejemplo: 1949 → \"1949\"\ndf['month'].astype(str) Convierte la columna month (tipo category) a texto. Ejemplo: \"Jan\" → \"Jan\"\ndf['year'].astype(str) + '-' + df['month'].astype(str) Concatena las dos columnas con un guion. Resultado: \"1949-Jan\"\npd.to_datetime(..., format='%Y-%b') Convierte esa cadena a una fecha usando el formato especificado:\n\n\n%Y → año con cuatro cifras (1949)\n%b → mes abreviado en inglés (Jan, Feb, Mar, etc.)\n\nVeamos ahora la columna que acabamos de crear:\n\ndf.head()\n\n\n\n\n\n\n\n\nyear\nmonth\npassengers\nfecha\n\n\n\n\n0\n1949\nJan\n112\n1949-01-01\n\n\n1\n1949\nFeb\n118\n1949-02-01\n\n\n2\n1949\nMar\n132\n1949-03-01\n\n\n3\n1949\nApr\n129\n1949-04-01\n\n\n4\n1949\nMay\n121\n1949-05-01\n\n\n\n\n\n\n\n\ndf['fecha_index'] = df['fecha']\n\n# Establecer 'fecha_index' como índice\ndf.set_index('fecha_index', inplace=True)\n\n# Verificar resultado\ndf.head()\n\n\n\n\n\n\n\n\nyear\nmonth\npassengers\nfecha\n\n\nfecha_index\n\n\n\n\n\n\n\n\n1949-01-01\n1949\nJan\n112\n1949-01-01\n\n\n1949-02-01\n1949\nFeb\n118\n1949-02-01\n\n\n1949-03-01\n1949\nMar\n132\n1949-03-01\n\n\n1949-04-01\n1949\nApr\n129\n1949-04-01\n\n\n1949-05-01\n1949\nMay\n121\n1949-05-01\n\n\n\n\n\n\n\nAhora ya podemos hacer un gráfico de series, y pandas colocará automáticamente las fechas en el eje X usando la columna index fecha_index:\n\ndf['passengers'].plot()\nplt.show()\n\n\n\n\n\n\n\n\nVamos a rotular el gráfico para mejorar la legibilidad\n\ndf['passengers'].plot(title='Pasajeros mensuales en vuelos comerciales', figsize=(10, 4))\nplt.ylabel('Número de pasajeros')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\ndf['media_movil'] = df['passengers'].rolling(window=12).mean()\n\ndf[['passengers', 'media_movil']].plot(title='Pasajeros y media móvil (12 meses)', figsize=(10, 4))\nplt.ylabel('Pasajeros')\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#cómo-leer-una-hoja-de-cálculo-en-google-colaborate",
    "href": "010-introduccion-a-python.html#cómo-leer-una-hoja-de-cálculo-en-google-colaborate",
    "title": "2  Introducción a Python (1)",
    "section": "2.12 Cómo leer una hoja de cálculo en Google Colaborate",
    "text": "2.12 Cómo leer una hoja de cálculo en Google Colaborate\n\nOpción 1: Subir los datos al espacio de trabajo de Google Colaborate\nLos pasos son los mismos tanto si queremos trabajar con un CSVo directamente con una hoja Excel: 1. Seleccionamos el icono de carpeta a la izquierda, que nos abre la barra lateral de Archivos 2. Hacemos click sobre el icono de la hoja con la flecha vertical, lo que nos abre una ventana de selección de archivos. 3. Seleccionamos la hoja de cálculo o CSVcon la que vamos a trabajar y la subimos al espacio de trabajo de Google Colaborate\nUna vez la hoja de cálculo o el CSV en nuestro espacio de trabajo, procedemos a leer los datos.\nEl mayor inconveniente de esta forma de trabajo es que cada vez que salimos de la sesión, Google Colab borra todos nuestros archivos del espacio de trabajo; cada vez que iniciemos una sesión, tendremos que repetir el proceso de subir nuestros datos al espacio de trabajo.\n\n\nOpción 2: Leer directamente los datos de nuestra carpeta de Google Drive\nEsta es una opción mucho más cómoda que nos evita los pasos intermedios, ya que no necesitamos subir la hoja de cálculo al espacio de trabajo.\nVeamos las dos alternativas:\n\nimport pandas as pd\n\n# Montar Google Drive si tu archivo está allí\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Ruta de tu archivo Excel. Asegúrate de que esta ruta sea correcta.\n# Si está en la raíz de tu Drive, sería algo así:\narchivo_excel = '/content/drive/MyDrive/ejemplo_muestreo.xlsx'\n\n# Si el archivo está directamente en el entorno de Colab (subido o creado allí),\n# la ruta podría ser simplemente el nombre del archivo si estás en el mismo directorio:\n# archivo_excel = 'ejemplo_muestreo.xlsx'\n\n\n# Leer el archivo Excel, especificando la hoja\ndf = pd.read_excel(archivo_excel, sheet_name=\"Hoja1\")\n\n# Mostrar las primeras filas del DataFrame para verificar\nprint(df.head())\n\n\n\nExplicación de los pasos:\n\nimport pandas as pd:\n\nEsta línea importa la librería pandas, que es fundamental para el manejo y análisis de datos en Python. Es una convención llamarla pd.\n\nMontar Google Drive (si es necesario):\n\nSi tu archivo ejemplo_muestreo.xlsx está almacenado en tu Google Drive, necesitas montar Drive en tu entorno de Colab para poder acceder a él. Las líneas from google.colab import drive y drive.mount('/content/drive') se encargan de esto.\nUna vez montado, tus archivos de Drive serán accesibles a través de la ruta /content/drive/MyDrive/.\n\narchivo_excel = '/content/drive/MyDrive/ejemplo_muestreo.xlsx':\n\nAquí defines la ruta completa de tu archivo Excel.\n¡Importante! Debes ajustar esta ruta a la ubicación real de tu archivo.\n\nSi lo tienes en Google Drive (y lo montaste), la ruta será similar a /content/drive/MyDrive/nombre_de_tu_carpeta/ejemplo_muestreo.xlsx.\nSi subiste el archivo directamente a Colab (usando el ícono de la carpeta en el panel izquierdo y luego “Subir”), y está en el directorio raíz de Colab, simplemente el nombre del archivo (ejemplo_muestreo.xlsx) debería funcionar.\n\n\ndf = pd.read_excel(archivo_excel, sheet_name=\"Hoja1\"):\n\nEsta es la función clave.\npd.read_excel() es el equivalente directo a read_excel() de readxl en R.\nEl primer argumento es la ruta al archivo Excel.\nsheet_name=\"Hoja1\" especifica qué hoja del libro de Excel quieres leer. Es el equivalente al argumento sheet = \"Hoja1\" en R. Puedes usar el nombre de la hoja o su índice (donde 0 es la primera hoja, 1 la segunda, etc.).\n\nprint(df.head()):\n\nUna vez que los datos se han cargado en un DataFrame de pandas (que es el objeto df), puedes usar df.head() para ver las primeras 5 filas y asegurarte de que los datos se cargaron correctamente. Esto es similar a head(df) en R.\n\n\nCon estos pasos, tendrás tus datos de Excel cargados en un DataFrame de pandas, listos para ser manipulados y analizados en Python.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "010-introduccion-a-python.html#resumen",
    "href": "010-introduccion-a-python.html#resumen",
    "title": "2  Introducción a Python (1)",
    "section": "2.13 Resumen",
    "text": "2.13 Resumen\nEn este capítulo hemos tomado contacto con python y su utilización a través de un interface Jupyter, en este caso Google Colaborate. Hemos visto los principales tipos de datos, particularmente el data frame, y hemos aprendido a leer datos que previamente se habían introducido en una hoja de cálculo. Ya estamos listos para empezar a utilizar python en el análisis de nuestros datos de producción.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a Python (1)</span>"
    ]
  },
  {
    "objectID": "020-introduccion-a-python.html",
    "href": "020-introduccion-a-python.html",
    "title": "3  Introduccion a Python (2)",
    "section": "",
    "text": "Como siempre, empezamos nuestro cuaderno importando las bibliotecas que vamos a usar en el ejercicio.\n\nimport os                       # # manejo de funciones del sistema\nimport sys                      # manejo de funciones del sistema\nimport pandas as pd             # manejo de dataframes y series\nimport numpy as np              # funciones de cálculo numérico de la biblioteca `numpy`\nimport matplotlib.pyplot as plt # funciones específicas de `matplotlib.pyplot`\nfrom scipy.stats import norm    # para hacer la curva de distribución normal\nimport locale                   # para poner las fechas en formato español\n\n\n# ajustamos fechas a formato español, el punto y coma evita la impresion de salida de la funcion\nlocale.setlocale(locale.LC_TIME, 'Spanish_Spain.1252');                                                \n\nImportamos también las funciones gráficas de la biblioteca seaborny establecemos un estilo por defecto, con el fondo blanco.\n\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nEs necesario cargar el fichero camembert.csv en el espacio de trabajo de Google Colaborate. Para ello, montamos nuestro drive y damos a Python el path (la direccion de la carpeta).\nUna vez cargado, verificamos que existe y hay acceso:\n\n# 1. Ejecuta esta celda para montar tu Google Drive.\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# 2. Verifica y ajusta esta ruta de archivo si es necesario:\ngoogle_drive_path_folder = '/content/drive/MyDrive/Colab Notebooks/master-queseria/datos/'\nnombre_archivo_base = 'camembert.csv'\nPATH_TO_READ = os.path.join(google_drive_path_folder, nombre_archivo_base)\n\nAunque podríamos hacer la lectura del fichero de datos con la instruccion simple,\n\ndf = pd.read_csv(\n        PATH_TO_READ, \n        sep = \";\", \n        decimal = \",\", \n        encoding = 'utf-8' # codificacion usada por Windows\n    )\n\nen Python siempre se prefiere encapsular la instrucción en una estructura try...except, que maneja los posibles errores o excepciones que pueden producirse en la lectura, por ejemplo, que nuestro path sea incorrecto, o que hayamos escrito mal el nombre del fichero, o cualquier otro error que haga que la instruccion de lectura falle. Añadimos también algunas instrucciones de print() que nos ayuden a saber que todo ha ido bien (o mal).\n\n# ----------------------------------------\n# Lectura de datos\n# ----------------------------------------\n\nprint(f\"Intentando leer el archivo desde la ruta: {PATH_TO_READ}\\n\")\n\ntry:\n    df = pd.read_csv(\n        PATH_TO_READ, \n        sep = \";\", \n        decimal = \",\", \n        encoding = 'utf-8'\n    )\n    print(\"--- LECTURA EXITOSA ---\")\n    print(f\"Filas cargadas: {len(df)}\")\n    df.head()\n    \nexcept FileNotFoundError:\n    print(\"\\n--- ERROR DE ARCHIVO ---\")\n    print(ERROR_MESSAGE_HELP)\n        \nexcept Exception as e:\n    print(\"\\n--- ERROR AL LEER EL CSV ---\")\n    print(\"Ocurrió un error al leer el archivo. Error: {e}\")\n\nIntentando leer el archivo desde la ruta: camembert.csv\n\n--- LECTURA EXITOSA ---\nFilas cargadas: 211\n\n\nAhora convertimos la primera columna, que pandas ha leido como texto, en una columna de fecha, y la asignamos como index del dataframe. Esto tendrá interés especial cuando usemos las funciones de pandaspara hacer nuestros gráficos de series; el formateo de series temporales en esta biblioteca es uno de sus puntos más fuertes.\n\ndf['fecha']= pd.DatetimeIndex(df.fecha).normalize()\ndf.set_index('fecha',inplace=True)\ndf.sort_index(inplace=True)\n\nPodemos mostrar el dataframe que hemos leído, mediante la funcion .head(), que nos muestra las cinco primeras lineas.\n\ndf.head()\n\n\n\n\n\n\n\n\nfabricacion\nest\nmg\nph\ncloruros\ncoliformes\n\n\nfecha\n\n\n\n\n\n\n\n\n\n\n2020-01-02\n1\n46.22\n23.0\n4.61\n1.88\n0.0\n\n\n2020-01-03\n1\n45.28\n23.0\n4.78\n1.62\n0.0\n\n\n2020-01-06\n1\n45.11\n23.0\n4.72\n1.69\n2000.0\n\n\n2020-01-08\n1\n49.05\n23.5\n4.68\n1.65\n6000.0\n\n\n2020-01-09\n1\n47.82\n25.0\n4.66\n1.37\n100.0\n\n\n\n\n\n\n\nVemos que el nombre de la columna fecha está colocada en una línea inferior respecto a los otros nombres de columna. Esto se debe a que la hemos designado como ìndex, y, por lo tanto, ya no es una columna ordinaria para pandas (podemos volver a convertirla en columna normal o de texto en cualquier momento según nuestros intereses, como veremos más adelante).\nTambién podemos usar la función .info(), que nos dice la estructura interna de nuestro dataframe y el tipo de los datos (entero, numérico, carácter…). Dado que la fecha, como hemos visto, está formateada como fecha y asignada como ìndex, ya no aparece en el listado de columnas de datos, sino que aparece en la primera línea como DateTimeIndex, y la informacion nos dice los límites de esas fechas.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 211 entries, 2020-01-02 to 2020-12-29\nData columns (total 6 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   fabricacion  211 non-null    int64  \n 1   est          211 non-null    float64\n 2   mg           211 non-null    float64\n 3   ph           211 non-null    float64\n 4   cloruros     211 non-null    float64\n 5   coliformes   210 non-null    float64\ndtypes: float64(5), int64(1)\nmemory usage: 11.5 KB\n\n\nUna vez leído correctamente el DataFrame, podemos hacer algunos gráficos de sus columnas numéricas. También usaremos las funciones de seaborn que producen salidas muy atractivas y son funcionjes fáciles de manejar.\n\ndf[\"est\"].hist() # histograma bássico de matplotlib\n\nplt.show()\n\n\n\n\n\n\n\n\nFíjate en la forma correcta de designar una columna en un DataFramede pandas, usando su nombre.\n\ndf[\"est\"].hist(bins = 5)\n\nplt.show()\n\n\n\n\n\n\n\n\nVamos a repetir el histograma con seaborn, que nos permite incluir una curva de densidad fácilmente (pregunta: ¿qué es una curva de densidad?)\n\nsns.displot(df[\"est\"], kde = True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.boxplot(df['est'])\n\nplt.show()\n\n\n\n\n\n\n\n\nAquí puedes ver la potencia de pandasparamanejar y agrupar las series. Para representar los datos por mes, sólo tenemos que crear una nueva columna mes indicando a pandas que extraiga del índice la parte de fecha que corresponde al mes. ¿Fácil, no?\n\ndf['mes'] = df.index.month\nsns.boxplot(x='mes', y='est', data=df)\n\nplt.show()\n\n\n\n\n\n\n\n\nEn vez de usar el número para el mes, podemos usar el código de letras abreviado (en este caso, seabornutiliza la abreviatura en inglés, pero hemos cambiado la codificación para que lo represente en español, en la instruccion locale que hemos usado en la primera casilla). Aprovechamos para personalizar un poco el gráfico.\n\ndf['mes_abreviado'] = df.index.strftime('%b')\nsns.boxplot(x='mes_abreviado', y='est', data=df)\n# Opcional: Personalizar el gráfico\nplt.title('Boxplot de la variable \"est\" por Mes')\nplt.xlabel('Mes')\nplt.ylabel('Valor de \"est\"')\nplt.grid(axis='y', linestyle='--', alpha=0.7) # Añadir una cuadrícula para mejor lectura\nplt.xticks(rotation=45) # Rotar las etiquetas del eje X si son muchas\nplt.tight_layout() # Ajusta automáticamente los parámetros de la subtrama para un diseño ajustado\n\nplt.show()\n\n\n\n\n\n\n\n\nLa función .plot() nos representa los valores de la columna en orden secuencial:\n\ndf[\"est\"].plot()\nplt.show()\n\n\n\n\n\n\n\n\nSi utilizamos las funciones de pandas, podemos reformatear las fechas como serie temporal. Creamos una serie temporal y la remuestreamos para hacer las medias semanales del extracto seco total, eliminando las semans en las que no hay valores con .dropna(). La función resample('W-MON') formatea las fechas para que las semanas empiecen en lunes, como es el caso en Europa (en USA la semana empieza el domingo). Aprovechamos para mostrar una de las potencias de Python: podemos hacer que varios cálculos se hagan a continuacion de los otros, simplemente enlazando las funciones, hasta el .plot()\n\nplt.rcParams['figure.figsize'] = (10.0,4.0)\nts = pd.Series(df[\"est\"].dropna())\nts.resample('W-MON').mean().plot(title=\"Media del extracto seco total semanal\")\nplt.show()\n\n\n\n\n\n\n\n\nVeamos a continuación otras formas de formatear la serie sobre la marcha, pero esta vez representando la desviación típicaen vez de la media.\n\nts.resample('W-MON').std().plot(title=\"Desviación típica del extracto seco total semanal\");\n\n\n\n\n\n\n\n\nO podemos representar un período específico de la serie indicando a pandas los límites inferior y superior de las fechas que queremos.\n\nts[\"2020-05\":\"2020-08\"].resample('W-MON').mean().plot(title=\"Media del extracto seco total semanal\");\n\n\n\n\n\n\n\n\nA modo ilustrativo, aunque sin un interés prioritario, muestro un grafico jointplot() de seaborn que muestra la facilidad con la que esta biblioteca puede hacer un gráfico complejo de dispersión e histograma simultáneamente.\n\nsns.jointplot(x=\"est\", y=\"mg\", data = df[~df.index.duplicated(keep='first')])\n\n\n\n\n\n\n\n\nUna alternativa más moderna a los boxplots son los llamados violin plots, que tienenla ventaja sobrelos primeros de mostrar la curva de distribución de los datos.\n\nsns.violinplot(y=df[\"est\"], x=df.index.month)\n\n\n\n\n\n\n\n\nFinalmente, una serie de cálculos más complejos para obtener los gráficos de capacidad de un proceso, como muestra de cómo se pueden usar las funciones y gráficos de Python para prácticamente cualquier necesidad.\n\n# codigo de Roberto Salazar\n# https://medium.com/geekculture/process-capability-analysis-with-python-a0f3aed8e578\n\n# Set specification limits\ntarget = 5\nLSL = 3\nUSL = 7\n\n# Generate normally distributed data points\ndata = np.random.normal(loc=target,scale=1,size=100)\n\n\n# Generate probability density function\nx = np.linspace(min(data), max(data), 1000)\ny = norm.pdf(x, loc=5, scale=1)\n\n# Plot histogram for data along with probability density functions and specification limits\nplt.figure(figsize=(10,5))\nplt.hist(data, color=\"lightgrey\", edgecolor=\"black\", density=True)\nsns.kdeplot(data, color=\"blue\", label=\"Density ST\")\nplt.plot(x, y, linestyle=\"--\", color=\"black\", label=\"Theorethical Density ST\")\nplt.axvline(LSL, linestyle=\"--\", color=\"red\", label=\"LSL\")\nplt.axvline(USL, linestyle=\"--\", color=\"orange\", label=\"USL\")\nplt.axvline(target, linestyle=\"--\", color=\"green\", label=\"Target\")\nplt.title('Process Capability Analysis')\nplt.xlabel(\"Measure\")\nplt.ylabel(\"\")\nplt.yticks([])\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate Cp\nCp = (USL-LSL)/(6*np.std(data))\n\n# Calculate Cpk\nCpk = min((USL-data.mean())/(3*data.std()), (data.mean()-LSL)/(3*data.std()))\n\n# Calculate z-value\nz = min((USL-data.mean())/(data.std()), (data.mean()-LSL)/(data.std()))\n\n# Get data summary statistics\nnum_samples = len(data)\nsample_mean = data.mean()\nsample_std = data.std()\nsample_max = data.max()\nsample_min = data.min()\nsample_median = np.median(data)\n\n# Get percentage of data points outside of specification limits\npct_below_LSL = len(data[data &lt; LSL])/len(data)*100\npct_above_USL = len(data[data &gt; USL])/len(data)*100\n\n# \"\"\" # Write .txt file with results\n# with open('/content/process_results.txt', \"w\") as results:\n#     results.write(\"PROCESS CAPABILITY ANALYSIS\\n\")\n\n#     results.write(\"-----------------------------------\\n\")\n#     results.write(f\"Specifications\\n\")\n#     results.write(f\"\\nTarget: {target}\\n\")\n#     results.write(f\"LSL: {LSL}\\n\")\n#     results.write(f\"USL: {USL}\\n\")\n\n#     results.write(\"-----------------------------------\\n\")\n#     results.write(f\"Indices\\n\")\n#     results.write(f\"\\nCp: {round(Cp,2)}\\n\")\n#     results.write(f\"Cpk: {round(Cpk,2)}\\n\")\n#     results.write(f\"z: {round(z,2)}\\n\")\n\n#     results.write(\"-----------------------------------\\n\")\n#     results.write(f\"Summary Statistics\\n\")\n#     results.write(f\"\\nNumber of samples: {round(num_samples,2)}\\n\")\n#     results.write(f\"Sample mean: {round(sample_mean,2)}\\n\")\n#     results.write(f\"Sample std: {round(sample_std,2)}\\n\")\n#     results.write(f\"Sample max: {round(sample_max,2)}\\n\")\n#     results.write(f\"Sample min: {round(sample_min,2)}\\n\")\n#     results.write(f\"Sample median: {round(sample_median,2)}\\n\")\n\n#     results.write(f\"Percentage of data points below LSL: {round(pct_below_LSL,2)}%\\n\")\n#     results.write(f\"Percentage of data points above USL: {round(pct_above_USL,2)}%\\n\") \"\"\"\n\nver https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot\nA continuación, una serie de celdas que realizan gráficos diversos, puedes dedicar un rato a estudiarlas e intentar comprender bien su programación.\n\nlimite_rechazo = 231    ##\nlimite_deficientes = 242    ##\n\nLSL = df.est.mean() - 3 * df.est.std()    ## lower specification limit\nUSL = df.est.mean() + 3 * df.est.std()    ## upper specification limit\n\ndf.insert(6,'LSL', LSL)\ndf.insert(7,'USL', USL)\n\n\ndf['fecha'] = df.index\n\n\ndf.head()\n\n\n\n\n\n\n\n\nfabricacion\nest\nmg\nph\ncloruros\ncoliformes\nLSL\nUSL\nmes\nmes_abreviado\nfecha\n\n\nfecha\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020-01-02\n1\n46.22\n23.0\n4.61\n1.88\n0.0\n42.279767\n50.994641\n1\nene.\n2020-01-02\n\n\n2020-01-03\n1\n45.28\n23.0\n4.78\n1.62\n0.0\n42.279767\n50.994641\n1\nene.\n2020-01-03\n\n\n2020-01-06\n1\n45.11\n23.0\n4.72\n1.69\n2000.0\n42.279767\n50.994641\n1\nene.\n2020-01-06\n\n\n2020-01-08\n1\n49.05\n23.5\n4.68\n1.65\n6000.0\n42.279767\n50.994641\n1\nene.\n2020-01-08\n\n\n2020-01-09\n1\n47.82\n25.0\n4.66\n1.37\n100.0\n42.279767\n50.994641\n1\nene.\n2020-01-09\n\n\n\n\n\n\n\n\ndf2 = pd.melt(df, id_vars= ['fecha'], value_vars=[\"est\",\"LSL\", \"USL\"],  value_name=\"valores\")\n\n\ndf2.head()\n\n\n\n\n\n\n\n\nfecha\nvariable\nvalores\n\n\n\n\n0\n2020-01-02\nest\n46.22\n\n\n1\n2020-01-03\nest\n45.28\n\n\n2\n2020-01-06\nest\n45.11\n\n\n3\n2020-01-08\nest\n49.05\n\n\n4\n2020-01-09\nest\n47.82\n\n\n\n\n\n\n\n\nplt.rcParams['figure.figsize'] = (10.0,4.0)\ng = sns.lineplot(data=df2, x=\"fecha\", y=\"valores\", hue=\"variable\")\n\n\n\n\n\n\n\n\n\ndf3 = df2.groupby([df2['fecha'].dt.isocalendar().week, \"variable\"]).mean()\n\n\ndf3.reset_index(inplace=True)\n\n\ndf3.head()\n\n\n\n\n\n\n\n\nweek\nvariable\nfecha\nvalores\n\n\n\n\n0\n1\nLSL\n2020-01-02 12:00:00\n42.279767\n\n\n1\n1\nUSL\n2020-01-02 12:00:00\n50.994641\n\n\n2\n1\nest\n2020-01-02 12:00:00\n45.750000\n\n\n3\n2\nLSL\n2020-01-08 18:00:00\n42.279767\n\n\n4\n2\nUSL\n2020-01-08 18:00:00\n50.994641\n\n\n\n\n\n\n\n\nplt.rcParams['figure.figsize'] = (10.0,4.0)\nsns.set_style(\"whitegrid\")\ng = sns.lineplot(data=df3, x=\"week\", y=\"valores\", hue=\"variable\")\n\n\n\n\n\n\n\n\n\ndf = pd.read_csv(\"camembert.csv\" , decimal = \",\", sep=\";\")\ndf['fecha']= pd.DatetimeIndex(df.fecha).normalize()\ndf.drop(['fabricacion','mg', 'cloruros','coliformes'], axis=1, inplace = True)\n\n\ndf2 = df['est'].groupby(df['fecha'].dt.isocalendar().week).agg(['mean','std'])\n\n\ndf2.head()\n\n\n\n\n\n\n\n\nmean\nstd\n\n\nweek\n\n\n\n\n\n\n1\n45.7500\n0.664680\n\n\n2\n47.3125\n1.646134\n\n\n3\n45.7700\n0.547494\n\n\n4\n46.5400\n0.893476\n\n\n5\n46.0150\n0.522986\n\n\n\n\n\n\n\n\ndf2['mean'].plot();\n\n\n\n\n\n\n\n\n\ndf2['std'].plot();\n\n\n\n\n\n\n\n\n\nLSL = df2['mean'] - 3 * df2['std']    ## lower specification limit\nUSL = df2['mean'] + 3 * df2['std']    ## upper specification limit\n\ndf2.insert(2,'LSL', LSL)\ndf2.insert(3,'USL', USL)\n\n# limite_rechazo = 231    ##\n# limite_deficientes = 242    ##\n# df3.insert(5,'rechazo', limite_rechazo)\n# df3.insert(6,'deficientes', limite_deficientes)\n\n\ndf2.head()\n\n\n\n\n\n\n\n\nmean\nstd\nLSL\nUSL\n\n\nweek\n\n\n\n\n\n\n\n\n1\n45.7500\n0.664680\n43.755959\n47.744041\n\n\n2\n47.3125\n1.646134\n42.374097\n52.250903\n\n\n3\n45.7700\n0.547494\n44.127517\n47.412483\n\n\n4\n46.5400\n0.893476\n43.859571\n49.220429\n\n\n5\n46.0150\n0.522986\n44.446042\n47.583958\n\n\n\n\n\n\n\n\ndf2['semana'] = df2.index # necesitamos la semana en una columna de valor\ndf3 = pd.melt(df2, id_vars= ['semana'], value_vars=[\"mean\",\"LSL\", \"USL\"],  value_name=\"valores\")\n\n\ng = sns.lineplot(data=df3, x=\"semana\", y=\"valores\", hue=\"variable\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduccion a Python (2)</span>"
    ]
  },
  {
    "objectID": "160-bibliografia.html",
    "href": "160-bibliografia.html",
    "title": "Bibliografía",
    "section": "",
    "text": "World Economic Forum. 2025. “Future of Jobs Report, 2025.”\n91-93 route de la Capite,CH-1223 Cologny/Geneva, Switzerland: World\nEconomic Forum. https://www.weforum.org/publications/the-future-of-jobs-report-2025/.",
    "crumbs": [
      "Anexos",
      "Bibliografía"
    ]
  }
]